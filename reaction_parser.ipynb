{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1c8d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "# import pdf2text as p2t\n",
    "# importlib.reload(p2t)\n",
    "import subprocess\n",
    "import json\n",
    "from rdkit import Chem\n",
    "from indigo import Indigo\n",
    "indigo = Indigo()\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 5000)\n",
    "pd.set_option('display.max_rows', 1500)\n",
    "import reactions_converter as rc\n",
    "importlib.reload(rc)\n",
    "import copy\n",
    "from itertools import permutations, combinations  \n",
    "import convert_to_docx as ctd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0700b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target structure\n",
    "reaction_dict = {\n",
    "                                                                                                                                    'doi': '', #дои статьи, откуда оно взялось\n",
    "    'reaction_rxn': '', #реакция в формате rxn\n",
    "    'products': [{'molfile': '',\n",
    "                  'amount': 0, #in mmol\n",
    "                  'weight': 0, #in g\n",
    "                  'vol': 0, #in mL\n",
    "                  'yield': 0 #in %\n",
    "                 }], #список словарей для нескольких продуктов\n",
    "    'reagents': [{'molfile': '',\n",
    "                  'role': '', #reactant, reagent, catalyst\n",
    "                  'amount': 0, #in mmol\n",
    "                  'weight': 0, #in g\n",
    "                  'vol': 0, #in mL\n",
    "                 }],\n",
    "    'scale': 0, # = максимальный amount среди продуктов\n",
    "    'temperature': [0], #темпеатура в градусах Цельсия. Список так как может быть несколько температур\n",
    "    'time': [0], #время реакции в часах. Список так как может быть несколько этапов\n",
    "    'misc': [''], #список строк со всякими остальными условиями '20 mA', '450 nm 400 W'\n",
    "    'solvent': [{'solvent_name': '', 'solvent_vol': 0}], #список словарей, где указаны объемы и названия растворителей\n",
    "    'protocol': '' #сюда тупо строкой падает методика\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0924b4c3",
   "metadata": {},
   "source": [
    "# Copy parsed protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16afbb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#copy files from parsed\n",
    "mistral_folder = '/media/oleg/second_ssd/rxn_parsing_data/processed'\n",
    "main_folder = '/media/oleg/second_ssd/rxn_parsing_data'\n",
    "for parse_id in tqdm(os.listdir(mistral_folder)):\n",
    "    #join splitted rxns\n",
    "    temp_res = []\n",
    "    for num_parts in os.listdir(os.path.join(mistral_folder, parse_id)):\n",
    "        with open(os.path.join(mistral_folder, parse_id, num_parts, 'reactions_parsed.json'), \n",
    "                  encoding = 'utf-8') as f:\n",
    "            temp_res += json.loads(f.read())\n",
    "    with open(os.path.join(main_folder, parse_id, 'reactions_parsed.json'),  'w', encoding = 'utf-8') as f:\n",
    "        f.write(json.dumps(temp_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c352a84d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54f97d11",
   "metadata": {},
   "source": [
    "# Save to docx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc0c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ctd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08bddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7b14c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "document = Document()\n",
    "for folder in tqdm(os.listdir('/media/oleg/second_ssd/temp_files_parser')):\n",
    "    folder_path = os.path.join('/media/oleg/second_ssd/temp_files_parser', folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        with open(os.path.join(folder_path, 'reactions_final.json')) as f:\n",
    "            reactions = json.loads(f.read())\n",
    "        ctd.get_doc_reactions(reactions, folder, document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055dd742",
   "metadata": {},
   "outputs": [],
   "source": [
    "document.save('/media/oleg/second_ssd/temp_files_parser/total_reactions_report.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f5a525",
   "metadata": {},
   "source": [
    "# Split total dataset to portions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab033edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_list = os.listdir('/media/oleg/hard_for_data/papers_for_parse/orglett/orglett_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbe1aa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(folder_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a67585",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = round(len(folder_list)/300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7757ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folder = '/media/oleg/second_ssd/rxn_parsing_data'\n",
    "for idx in range(num_batches+1):\n",
    "    sample = folder_list[idx*300: (idx+1)*300]\n",
    "    with open(os.path.join(target_folder, str(idx)+'_input.json'), 'w') as f:\n",
    "        f.write(json.dumps(sample))\n",
    "    print(len(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61c52a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list = [idx for idx in range(num_batches+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cea76c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f194e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/media/oleg/second_ssd/rxn_parsing_data/file_index.txt', 'w') as f:\n",
    "    f.writelines([str(x) + '\\n' for x in  idx_list[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7b6794",
   "metadata": {},
   "outputs": [],
   "source": [
    "/media/oleg/second_ssd/rxn_parsing_data/0/10.1021_ol9024309/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f36f89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = '/media/oleg/second_ssd/rxn_parsing_data/0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2959134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1627d7cd",
   "metadata": {},
   "source": [
    "# Copy files to server HSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94069cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_ids = range(34, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13f9525",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_files = [os.path.join('/media/oleg/second_ssd/rxn_parsing_data', str(x) + '_input.json') for x in parse_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155034af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de7c99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_list = []\n",
    "for inp_file in target_files:\n",
    "    with open(inp_file) as f:\n",
    "        folder_list += json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc13d321",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(folder_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b8d9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_folder = '/media/oleg/hard_for_data/papers_for_parse/orglett/orglett_full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912320eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_list = [os.path.join(global_folder, x) for x in folder_list ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9317c176",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/media/oleg/second_ssd/rxn_parsing_data/34_99_inputs.txt', 'w') as f:\n",
    "    f.writelines([fname+'\\n' for fname in folder_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745d1a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(126, 127):\n",
    "    if idx %2 == 0:\n",
    "        parse_ids = [str(x) for x in [idx,idx+1]]\n",
    "        string = f\"\"\"#! /bin/bash\n",
    "#SBATCH --job-name=\"{'_'.join(parse_ids)}_data_prep\"\n",
    "#SBATCH --gpus=1\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --time=0-24:0\n",
    "#SBATCH --output=\"stdout.%j.txt\"%j.out\n",
    "#SBATCH --error=\"stderr.%j.txt\"%j.out\n",
    "module purge\n",
    "module load Python/Anaconda_v11.2021\n",
    "\n",
    "source deactivate\n",
    "source activate molscribe\n",
    "\n",
    "nvidia-smi\n",
    "\n",
    "global_folder=\"/home/dchusov/inp_data/orglett\"\n",
    "result_folder=\"/home/dchusov/temp_parsing_data\"\n",
    "\n",
    "for input_idx in {' '.join(parse_ids)}\n",
    "do\n",
    "temp_folder=$result_folder/$input_idx\n",
    "echo \"Start processing \" \n",
    "echo \"creating temp folders and making pngs and texts\" \n",
    "mkdir $temp_folder\n",
    "python /home/dchusov/reaction_parser/create_text_image_mp.py $global_folder $temp_folder &\n",
    "sleep 1000\n",
    "echo \"running opsin in parallel with creation of text and images\"\n",
    "python /home/dchusov/reaction_parser/running_opsing.py $temp_folder &\n",
    "sleep 40\n",
    "echo \"running mols recognition\"\n",
    "python /home/dchusov/ocsr_molscribe_mp/recognize_mols.py $temp_folder\n",
    "done\"\"\"\n",
    "        with open(os.path.join('/media/oleg/second_ssd/rxn_parsing_data/sbatches_for_ocr', \n",
    "                               '_'.join(parse_ids) + '_ocr.sbatch'), 'w') as f:\n",
    "            f.write(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f85f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_folder=\"/home/dchusov/temp_parsing_data\"\n",
    "\n",
    "for input_idx in 34 46 47 67 72 73 74 90 91 92 93 94 95 96 97 98 99 100 101 117 126\n",
    "do\n",
    "temp_folder=$result_folder/$input_idx\n",
    "echo \"process $input_idx\" \n",
    "zip -r $input_idx\".zip\" $temp_folder\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed8a090",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"\"\"#! /bin/bash\n",
    "#SBATCH --job-name=\"35_data_prep\"\n",
    "#SBATCH --gpus=1\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --time=0-24:0\n",
    "#SBATCH --output=\"stdout.%j.txt\"%j.out\n",
    "#SBATCH --error=\"stderr.%j.txt\"%j.out\n",
    "module purge\n",
    "module load Python/Anaconda_v11.2021\n",
    "\n",
    "source deactivate\n",
    "source activate molscribe\n",
    "\n",
    "nvidia-smi\n",
    "global_folder=\"/home/dchusov/inp_data/orglett\"\n",
    "result_folder=\"/home/dchusov/temp_parsing_data\"\n",
    "\n",
    "input_idx=34\n",
    "temp_folder=$result_folder/$input_idx\n",
    "echo \"Start processing\" \n",
    "echo \"creating temp folders and making pngs and texts\" \n",
    "mkdir $temp_folder\n",
    "python /home/dchusov/reaction_parser/create_text_image_mp.py $global_folder $temp_folder &\n",
    "sleep 1000\n",
    "echo \"running opsin in parallel with creation of text and images\"\n",
    "python /home/dchusov/reaction_parser/running_opsing.py $temp_folder &\n",
    "sleep 40\n",
    "echo \"running mols recognition\"\n",
    "python /home/dchusov/ocsr_molscribe_mp/recognize_mols.py $temp_folder\n",
    "\"\"\"\n",
    "print(string)\n",
    "\n",
    "with open(os.path.join('/media/oleg/second_ssd/rxn_parsing_data/sbatches_for_ocr', \n",
    "                       '35_ocr.sbatch'), 'w') as f:\n",
    "    f.write(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b93c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fda1b76",
   "metadata": {},
   "source": [
    "# Check full processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088895fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#is df_subs_mols.csv exists\n",
    "folder = '/media/oleg/second_ssd/rxn_parsing_data'\n",
    "for file in os.listdir(folder):\n",
    "    if os.path.isdir(os.path.join(folder,    file)):\n",
    "        if not os.path.exists(os.path.join(folder, file, 'df_subs_mols.csv')):\n",
    "            print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaaeb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#is df_subs_mols.csv exists\n",
    "folder = '/media/oleg/second_ssd/rxn_parsing_data'\n",
    "for file in os.listdir(folder):\n",
    "    if os.path.isdir(os.path.join(folder,    file)):\n",
    "        if not os.path.exists(os.path.join(folder, file, file+ '_1')):\n",
    "            print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df544cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#is reactions_parsed.json exists\n",
    "folder = '/media/oleg/second_ssd/rxn_parsing_data/processed'\n",
    "for parse_id in os.listdir(folder):\n",
    "    if os.path.isdir(os.path.join(folder, parse_id)):\n",
    "        for subfolder in os.listdir(os.path.join(folder, parse_id)):\n",
    "            if not os.path.exists(os.path.join(folder, parse_id, subfolder, 'reactions_parsed.json')):\n",
    "                print(parse_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914dc8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find rest folders\n",
    "folder = '/media/oleg/second_ssd/rxn_parsing_data'\n",
    "for idx in range(0, 127):\n",
    "    if not os.path.exists(os.path.join(folder, str(idx))):\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c2a336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check processed\n",
    "folder = '/media/oleg/second_ssd/rxn_parsing_data/processed'\n",
    "for idx in range(0, 127):\n",
    "    if not os.path.exists(os.path.join(folder, str(idx))):\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4005737",
   "metadata": {},
   "source": [
    "# Creating reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825e68a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from sys import argv\n",
    "import os\n",
    "\n",
    "from rdkit import Chem\n",
    "from indigo import Indigo\n",
    "indigo = Indigo()\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import reactions_converter as rc\n",
    "\n",
    "import copy\n",
    "from itertools import permutations, combinations  \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6a6361",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d001a630",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main_folder = '/media/oleg/second_ssd/rxn_parsing_data'\n",
    "for parse_id in tqdm(os.listdir(main_folder)):\n",
    "    if not os.path.isdir(os.path.join(main_folder, parse_id)):\n",
    "        continue\n",
    "    if not os.path.exists(os.path.join(main_folder, parse_id, 'reactions_parsed.json')):\n",
    "        continue\n",
    "        \n",
    "    global_folder = os.path.join(main_folder, parse_id)\n",
    "    \n",
    "    # folder_name = '10.1039_c8ob02305k'\n",
    "    for folder_name in os.listdir(global_folder):\n",
    "        folder = os.path.join(global_folder, folder_name)\n",
    "        if not os.path.isdir(folder):\n",
    "            continue\n",
    "        if not os.path.exists(os.path.join(folder, 'protocols.json')):\n",
    "            continue\n",
    "        if os.path.exists(os.path.join(folder, 'bad_reactions_final.json')):\n",
    "            continue  #already done\n",
    "        \n",
    "\n",
    "        with open(os.path.join(folder, 'joint_sorted_dict.json')) as f:\n",
    "            joint_sorted_dict = json.loads(f.read())\n",
    "        with open(os.path.join(folder, 'compid_descr.json')) as f:\n",
    "            compid_descr = json.loads(f.read()) \n",
    "        with open(os.path.join(folder, 'code2compid.json')) as f:\n",
    "            code2compid = json.loads(f.read()) \n",
    "        with open(os.path.join(folder, 'compid2name.json')) as f:\n",
    "            compid_to_name = json.loads(f.read()) \n",
    "        with open(os.path.join(global_folder, 'reactions_parsed.json')) as f:\n",
    "            protocols = json.loads(f.read())\n",
    "        protocols = [x for x in protocols if x['init_paper'] == folder_name]\n",
    "        \n",
    "        #clean comp dicts\n",
    "        compid_to_del = []\n",
    "        for compid, smiles in compid_descr.items():\n",
    "            try:\n",
    "                mol = indigo.loadMolecule(smiles)\n",
    "                mwt = mol.molecularWeight()\n",
    "            except:\n",
    "                compid_to_del.append(compid)        \n",
    "        \n",
    "        for compid in compid_to_del:\n",
    "            compid_descr.pop(compid, None)\n",
    "            compid_to_name.pop(compid, None)\n",
    "            codes2del = []\n",
    "            for code in code2compid:\n",
    "                if code2compid[code] == compid:\n",
    "                    codes2del.append(code)\n",
    "            for code in codes2del:\n",
    "                code2compid.pop(code, None)\n",
    "            name2del = []\n",
    "            for name in joint_sorted_dict:\n",
    "                if joint_sorted_dict[name] == compid:\n",
    "                    name2del.append(name)\n",
    "            for name in name2del:\n",
    "                joint_sorted_dict.pop(name, None)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print('Initial of protocols for ', parse_id, folder_name, ':', len(protocols))\n",
    "        transformed_protocols = []\n",
    "        for protocol in protocols:\n",
    "            try:\n",
    "                transformed_protocols += rc._transform_reaction_dict(protocol) #extract reagents names and reorganize naming\n",
    "            except Exception as e:\n",
    "                pass #print(e, '\\n', protocol)\n",
    "        for idx, item in enumerate(transformed_protocols):\n",
    "            item['is_general'] = rc._is_general(item['procedure'], item['procedure_name'])\n",
    "            item['id'] = idx\n",
    "        gen_prot_dict = {}\n",
    "        for item in transformed_protocols:\n",
    "            item['refers_to'] = []\n",
    "            if item['is_general']:\n",
    "                for name in list(set(item['procedure_name'])):\n",
    "                    gen_prot_dict[name] = item['id']\n",
    "            else:\n",
    "                for gp_name in gen_prot_dict:\n",
    "                    if gp_name.replace(' ', '') in item['procedure'].replace(' ', ''):\n",
    "                        item['refers_to'].append(gen_prot_dict[gp_name])\n",
    "\n",
    "        reactions = []\n",
    "        gen_proc_cond = {} # {idx: {'conditions': conditions, 'protocol': procedure}}\n",
    "\n",
    "        used_idx = []\n",
    "        for reaction in transformed_protocols:\n",
    "            reaction_created = False\n",
    "\n",
    "            if reaction['is_general']:\n",
    "                #в этом случае из протокола сохраняем отдельно условия, MiscInch и растворители\n",
    "                misc_solv_list = []\n",
    "                for comp in reaction['compounds']:\n",
    "                    if comp['compound_role'] != 'target': \n",
    "                        misc_solv_list.append(comp)\n",
    "\n",
    "                gp_ent = {'procedure': reaction['procedure'],\n",
    "                          'conditions': reaction['conditions'],\n",
    "                          'misc_solv_list': misc_solv_list } #=solv_gen\n",
    "                gen_proc_cond[reaction['id']] = gp_ent\n",
    "\n",
    "            elif len(reaction['refers_to']) > 0:\n",
    "                #дополняем реакцию условиями из общей методики\n",
    "                for gen_proc_id in reaction['refers_to']:\n",
    "                    reaction['conditions'] += gen_proc_cond[gen_proc_id]['conditions']\n",
    "\n",
    "                    #check if there are compounds in gen_proc duplicate already mentioned compounds in reaction\n",
    "                    existing_comps_with_amounts = []\n",
    "                    for comp in reaction['compounds']:\n",
    "                        if 'amounts' not in comp:\n",
    "                            comp['amounts'] = []\n",
    "                        if len(comp['amounts']) > 0:\n",
    "                            existing_comps_with_amounts.append(comp['compound_id'])\n",
    "                    appending_comps = []\n",
    "                    for comp in gen_proc_cond[gen_proc_id]['misc_solv_list']:\n",
    "                        if comp['compound_id'] not in existing_comps_with_amounts:\n",
    "                            appending_comps.append(comp)\n",
    "\n",
    "                    reaction['compounds'] = appending_comps + reaction['compounds'] #ставим общие условия в начале            \n",
    "            reaction_smi = rc._transform_reaction_combs(reaction, compid_descr, code2compid, compid_to_name)\n",
    "\n",
    "            reaction_smi['initial_protocol'] = reaction['procedure']\n",
    "            reaction_smi['used_idx'] = reaction['idx'] if type(reaction['idx']) == list else [reaction['idx']]\n",
    "            reactions.append(reaction_smi)\n",
    "\n",
    "        used_idx = []\n",
    "        final_rxn_list = []\n",
    "        for reaction in reactions:\n",
    "            if rc._is_true_reaction(reaction):\n",
    "                already_added = False\n",
    "                for idx in reaction['used_idx']:\n",
    "                    if idx in used_idx:\n",
    "                        already_added = True\n",
    "\n",
    "                if not already_added:\n",
    "                    final_rxn_list.append(reaction)\n",
    "                    used_idx += reaction['used_idx']\n",
    "\n",
    "        for reaction in reactions:\n",
    "            if rc._is_true_product(reaction):\n",
    "                already_added = False\n",
    "                for idx in reaction['used_idx']:\n",
    "                    if idx in used_idx:\n",
    "                        already_added = True\n",
    "\n",
    "                if not already_added:\n",
    "                    final_rxn_list.append(reaction)\n",
    "                    used_idx += reaction['used_idx']\n",
    "        print('Adequate reactions found', len(final_rxn_list))\n",
    "        \n",
    "        #saving all other reactions\n",
    "        bad_reactions = []\n",
    "        for reaction in reactions:\n",
    "            already_added = False\n",
    "            for idx in reaction['used_idx']:\n",
    "                if idx in used_idx:\n",
    "                    already_added = True        \n",
    "            if not already_added:\n",
    "                bad_reactions.append(reaction)\n",
    "                used_idx += reaction['used_idx']\n",
    "        \n",
    "        for rxn in final_rxn_list:\n",
    "            rxn.pop('rxn', None) \n",
    "        for rxn in bad_reactions:\n",
    "            rxn.pop('rxn', None)         \n",
    "        print(folder_name, ':', len(bad_reactions), 'bad reactions', '\\n')\n",
    "        with open(os.path.join(folder, 'reactions_final.json'), 'w', encoding = 'utf-8') as f:\n",
    "            f.write(json.dumps(final_rxn_list))\n",
    "        with open(os.path.join(folder, 'bad_reactions_final.json'), 'w', encoding = 'utf-8') as f:\n",
    "            f.write(json.dumps(bad_reactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5efb4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a84fb9d2",
   "metadata": {},
   "source": [
    "# Merging reactions thorughout the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "663dab27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 127/127 [04:18<00:00,  2.03s/it]\n"
     ]
    }
   ],
   "source": [
    "total_good_rxn = []\n",
    "total_bad_rxn = []\n",
    "folder='/media/oleg/second_ssd/rxn_parsing_data'\n",
    "for parse_id in tqdm(range(127)):\n",
    "    for subfolder in os.listdir(os.path.join(folder, str(parse_id))):\n",
    "        if os.path.exists(os.path.join(folder, str(parse_id), subfolder, 'reactions_final.json')):\n",
    "            with open(os.path.join(folder, str(parse_id), subfolder, 'reactions_final.json')) as f:\n",
    "                new_good_rxns = json.loads(f.read())\n",
    "                for item in new_good_rxns:\n",
    "                    item['ref'] = subfolder\n",
    "                total_good_rxn += new_good_rxns\n",
    "            with open(os.path.join(folder, str(parse_id), subfolder, 'bad_reactions_final.json')) as f:\n",
    "                new_bad_rxns = json.loads(f.read())\n",
    "                for item in new_bad_rxns:\n",
    "                    item['ref'] = subfolder\n",
    "                total_bad_rxn += new_bad_rxns        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a81b6d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/media/oleg/second_ssd/rxn_parsing_data/good_rxns.json', 'w') as f:\n",
    "    f.write(json.dumps(total_good_rxn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38a71066",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/media/oleg/second_ssd/rxn_parsing_data/bad_rxns.json', 'w') as f:\n",
    "    f.write(json.dumps(total_bad_rxn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0eb517cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "860896"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_bad_rxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d839e744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487503"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_good_rxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90dfd3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'procedure': ' (Angew. Chem. Chem. 2: A solution of  4-bromobenzonitrile  (0.91 g, 5 mmol),  DIPEA  (2 mL, 15 mmol),  Pd(OAc)2  (25 mg, 2 mol%), DPEDhos (65 mg, 2.4 mol%) and  n-Butyl vinyl ether  in  BuOH  was stirred at 95 oC for 1 h. The solution was evaporated under reduced pressure. The residue was purified by flash column chromatography on silica_gel ( hexane  /  AcOEt  = 200:1 to 100:1) to afford 0.54 g (2.7 mmol, 54%) of 1u as a colorless oil. ',\n",
       " 'conditions': [{'temperature': 95.0}, {'time': 1.0}],\n",
       " 'compounds': [{'score': 1.5499999999999998,\n",
       "   'smiles': 'BrC1=CC=C(C#N)C=C1',\n",
       "   'compound_role': 'REACTANT',\n",
       "   'digit_amounts': {'mass': 910.0, 'amount': 5.0, 'mol%': 100.0}},\n",
       "  {'score': 1.0499999999999998,\n",
       "   'smiles': 'C(C)(C)N(CC)C(C)C',\n",
       "   'compound_role': 'REACTANT',\n",
       "   'digit_amounts': {'volume': 2.0,\n",
       "    'amount': 15.0,\n",
       "    'mol%': 300.0,\n",
       "    'mass': 1938.0}},\n",
       "  {'score': -0.3,\n",
       "   'smiles': 'InChI=1S/2C2H4O2.Pd/c2*1-2(3)4;/h2*1H3,(H,3,4);/q;;+2/p-2',\n",
       "   'compound_role': 'CATALYST',\n",
       "   'digit_amounts': {'mass': 25.0, 'mol%': 2.0, 'amount': 0.1114}},\n",
       "  {'score': 0,\n",
       "   'smiles': 'C(=C)OCCCC',\n",
       "   'compound_role': 'UNKNOWN',\n",
       "   'digit_amounts': {}},\n",
       "  {'score': 0,\n",
       "   'smiles': 'C(CCC)O',\n",
       "   'compound_role': 'SOLVENT',\n",
       "   'digit_amounts': {}},\n",
       "  {'score': 0,\n",
       "   'smiles': 'CCCCCC',\n",
       "   'compound_role': 'SOLVENT',\n",
       "   'digit_amounts': {}},\n",
       "  {'score': 0,\n",
       "   'smiles': 'C(C)(=O)OCC',\n",
       "   'compound_role': 'SOLVENT',\n",
       "   'digit_amounts': {}},\n",
       "  {'score': 3.5500000000000003,\n",
       "   'smiles': 'C(CCC)OC(=C)C1=CC=C(C#N)C=C1',\n",
       "   'compound_role': 'PRODUCT',\n",
       "   'digit_amounts': {'mass': 540.0, 'amount': 2.7, 'mol%': 54.0},\n",
       "   'ratio_amount_equiv': 20}],\n",
       " 'score': 11.803256375882123,\n",
       " 'smiles': 'BrC1C=CC(C#N)=CC=1.C(N(C(C)C)CC)(C)C.CC([O-])=O.CC([O-])=O.[Pd+2].C(OCCCC)=C>>C(OC(C1C=CC(C#N)=CC=1)=C)CCC |f:2.3.4|',\n",
       " 'scale': 5.0,\n",
       " 'score_dict': {'score_compounds': 2.3,\n",
       "  'product_exists': 3.5500000000000003,\n",
       "  'element_score': 0.3900318300822354,\n",
       "  'elem_score_dict': {'C': 2.143950054192168,\n",
       "   'H': 0.002743902489813613,\n",
       "   'N': 0.650053050137059},\n",
       "  'sm_atom_masses': {'C': 900.6019699999999,\n",
       "   'H': 115.87921,\n",
       "   'Br': 399.48189,\n",
       "   'N': 140.03692999999998},\n",
       "  'tm_atom_masses': {'C': 775.79134,\n",
       "   'H': 75.12063,\n",
       "   'N': 69.59356,\n",
       "   'O': 79.49448},\n",
       "  'score_chemo': 6.713224545799887,\n",
       "  'score_xgb': 0.5,\n",
       "  'total_score': 11.803256375882123},\n",
       " 'dist_before': 0,\n",
       " 'initial_protocol': ' (Angew. Chem. Chem. 2: A solution of  Compound_51  (0.91 g, 5 mmol),  MiscInch_7  (2 mL, 15 mmol),  MiscInch_12  (25 mg, 2 mol%), DPEDhos (65 mg, 2.4 mol%) and  Compound_17  in  Solvent_20  was stirred at 95 oC for 1 h. The solution was evaporated under reduced pressure. The residue was purified by flash column chromatography on silica_gel ( Solvent_44  /  Solvent_28  = 200:1 to 100:1) to afford 0.54 g (2.7 mmol, 54%) of 1u as a colorless oil. ',\n",
       " 'used_idx': [11],\n",
       " 'ref': '10.1021_acs.orglett.7b03858'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_good_rxn[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebb9251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a387e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ctd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d3867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder='/media/oleg/second_ssd/rxn_parsing_data'\n",
    "doc_idx = 0\n",
    "document_good = Document()\n",
    "document_bad = Document()\n",
    "curr_len = 0\n",
    "\n",
    "for parse_id in tqdm(range(127)):\n",
    "    for subfolder in os.listdir(os.path.join(folder, str(parse_id))):\n",
    "        if os.path.exists(os.path.join(folder, str(parse_id), subfolder, 'reactions_final.json')):\n",
    "            with open(os.path.join(folder, str(parse_id), subfolder, 'reactions_final.json'), encoding = 'utf-8') as f:\n",
    "                temp_good_rxn = json.loads(f.read())\n",
    "            ctd.get_doc_reactions(temp_good_rxn, subfolder, document_good)\n",
    "            curr_len+= len(temp_good_rxn )\n",
    "            with open(os.path.join(folder, str(parse_id), subfolder, 'bad_reactions_final.json'), encoding = 'utf-8') as f:\n",
    "                temp_bad_rxn = json.loads(f.read())         \n",
    "            ctd.get_doc_reactions(temp_bad_rxn, subfolder, document_bad)\n",
    "        if curr_len > 5000:\n",
    "            curr_len = 0\n",
    "            document_good.save(os.path.join(folder, str(doc_idx) + '_good.docx'))\n",
    "            document_bad.save(os.path.join(folder, str(doc_idx) + '_bad.docx')) \n",
    "            doc_idx += 1\n",
    "            document_good = Document()\n",
    "            document_bad = Document()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d689cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81709281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa99fcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_good_rxn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fa087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import convert_to_docx as ctd\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26126a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = Document()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d418cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd.get_doc_reactions(total_good_rxn[:10], 'doi', document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0893c5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "document.save('test.doc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c4d9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
